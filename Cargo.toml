[package]
name = "tokenizers"
version = "1.22.1"
edition = "2021"

[lib]
crate-type = ["staticlib"]

[dependencies]
libc = "0.2.162"
tokenizers = { version = "0.20.0", features = ["http"] }
tiktoken-rs = "0.7.0"
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0.140"
base64 = "0.22"
rustc-hash = "1.1.0"
minijinja = { version = "2.2.0", features = ["json", "loop_controls"] }
minijinja-contrib = { version = "2.0.2", features = ["pycompat"] }
chrono = "0.4"
tracing = "0.1"
anyhow = "1.0"
thiserror = "1.0.48"
utoipa = { version = "4.2.0", features = ["axum_extras"] }

[dev-dependencies]
criterion = { version = "0.5.1", features = ["html_reports"] }
rand = "0.8.5"

[[bench]]
name = "decode_benchmark"
harness = false
